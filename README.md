# ğŸ§  Crafter Reinforcement Learning Project (A2C & Recurrent PPO)

This project implements and evaluates two reinforcement learning agents â€” **A2C** and **Recurrent PPO (CnnLSTM)** â€” in the **Crafter** environment. The aim is to iteratively improve each agent and compare their performance using standard Crafter metrics.

---

## ğŸ“ Project Structure

```bash
Reinforcement-Learning-Project-2026-Crafter/
â”‚
â”œâ”€â”€ train_a2c.py               # Training script for A2C agent with 2 improvements
â”œâ”€â”€ train_rppo.py              # Training script for Recurrent PPO with 2 improvements
â”œâ”€â”€ eval_a2c.py                # Evaluation script for A2C models
â”œâ”€â”€ eval_rppo.py               # Evaluation script for RPPO models
â”œâ”€â”€ utils.py                   # Shared utilities (env wrapper, plotting, reward shaping, etc.)
â”‚
â”œâ”€â”€ models/                    # Saved models (.zip or .pth)
â”‚   â”œâ”€â”€ a2c_baseline.zip
â”‚   â”œâ”€â”€ a2c_imp1.zip
â”‚   â”œâ”€â”€ a2c_imp2.zip
â”‚   â”œâ”€â”€ rppo_baseline.zip
â”‚   â”œâ”€â”€ rppo_imp1.zip
â”‚   â””â”€â”€ rppo_imp2.zip
â”‚
â”œâ”€â”€ logs/                      # Logging folders for evaluation and plots
â”‚   â”œâ”€â”€ a2c_baseline/
â”‚   â”œâ”€â”€ a2c_imp1/
â”‚   â”œâ”€â”€ a2c_imp2/
â”‚   â”œâ”€â”€ rppo_baseline/
â”‚   â”œâ”€â”€ rppo_imp1/
â”‚   â””â”€â”€ rppo_imp2/
â”‚
â”œâ”€â”€ report.pdf                 # Final written report for the assignment
â””â”€â”€ README.md                  # Project guide (this file)
```
---

## ğŸ› ï¸Installation Instructions
### 1. Clone the repo
```bash
git clone https://github.com/rchimome/Crafter.git
cd Crafter_Project
```
### 2. Set up virtual environment (optional but recommended)
```bash
python -m venv .venv
.\.venv\Scripts\activate  # Windows
```
### 3. Install dependencies
```bash
pip install -r requirements.txt
```
If using gymnasium, make sure to also install:
```bash
pip install gym==0.21.0 stable-baselines3[extra]
```

---

## ğŸ“Œ Notes
- All training uses 500,000 timesteps per agent iteration.
- Models are saved in .zip or .pth depending on implementation.
- Logs are grouped by iteration (logs/a2c_imp1/, etc.) for easy evaluation comparison.

---

## ğŸ‘¨â€ğŸ“ Contributors
- Christopher Musiiwa â€” Student Number: 707982
---
## ğŸ“ License
- This project is for academic use only as part of the MSc AI Reinforcement Learning coursework at Wits University (2026).
---
